{
 "metadata": {
  "name": "",
  "signature": "sha256:9cc3ce5b7faad92503bc48600b28b70f003924fd3bd024545b4cdb9b09042393"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#LOLNLP GIF Recommendation\n",
      "Arvind Narayanan, Tom Silver, Ved Topkar\n",
      "\n",
      "## Overview\n",
      "\n",
      "In this project, we set out to create a GIF recommender that can recommend relavent GIFs from an input piece of text. We realized that the corpus of GIF \"listicles\" on BuzzFeed made for the perfect training set of text associated with a large number of GIFs. We also realized that classifying a GIF with a specific emotion or range of emotions is a task that cannot be done very well by machine learning algorithms alone. Consequently, we split this project up into the following parts:\n",
      "\n",
      "1. Web Scraping\n",
      "    1. Crawling BuzzFeed for GIF Listicles\n",
      "    2. [Scraping Articles for GIFs and Tags](#buzzfeed-scraping)\n",
      "    3. Scraping Giphy for supplemental GIFs\n",
      "2. Crowdsourced GIF Sentiment Tagging\n",
      "    1. Building the Crowdsourcing Site\n",
      "    2. GIF Image Analysis\n",
      "3. Natural Language Processing\n",
      "    1. Parts of Speech Tagging\n",
      "    2. De Novo Sentiment Analysis\n",
      "    3. Dictionary-Based Sentiment Analysis\n",
      "    4. Content Analysis\n",
      "4. Recommendation Engine"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"buzzfeed-scraping\"></a>\n",
      "# Web Scraping"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scraping BuzzFeed\n",
      "\n",
      "Once we have a list of a large number of BuzzFeed GIF articles, we scraped each of them individually for the article title, each GIF, and each GIF's associated text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urlfile = open('data/buzzfeed_gif_links.txt','r')\n",
      "pages = {}\n",
      "for line in urlfile:\n",
      "    line = 'http://www.buzzfeed.com/' + line.replace('\\n','')\n",
      "    if not(line in pages):\n",
      "        pages[line] = 1\n",
      "urlfile_new = open('data/buzzfeed_gif_links_pt2.txt','r')\n",
      "for line in urlfile_new:\n",
      "    line = 'http://www.buzzfeed.com/' + line.replace('\\n','')\n",
      "    if not(line in pages):\n",
      "        pages[line] = 1\n",
      "gifs = []\n",
      "for page in pages:\n",
      "    gifs.append(newscrapepage(page))\n",
      "bf = [item for sublist in gifs for item in sublist]\n",
      "df = pd.DataFrame(bf)\n",
      "df.to_csv('data/buzzfeed_gifs_final.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "buzzfeed_gifs = pd.read_csv('data/buzzfeed_gifs_final.csv',encoding='utf-8')\n",
      "buzzfeed_gifs.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>Text</th>\n",
        "      <th>Title</th>\n",
        "      <th>URL</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1. Because I just wasn\u2019t one of those people w...</td>\n",
        "      <td> 18 Reasons Why Choosing A College Major Is Imp...</td>\n",
        "      <td> http://s3-ec.buzzfed.com/static/2014-05/enhanc...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2. Because there are SO many options to choose...</td>\n",
        "      <td> 18 Reasons Why Choosing A College Major Is Imp...</td>\n",
        "      <td> http://s3-ec.buzzfed.com/static/2014-05/enhanc...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td> 3. Some days you hate every subject in the wor...</td>\n",
        "      <td> 18 Reasons Why Choosing A College Major Is Imp...</td>\n",
        "      <td> http://s3-ec.buzzfed.com/static/2014-05/enhanc...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> 4. And other days you\u2019re super ambitious and t...</td>\n",
        "      <td> 18 Reasons Why Choosing A College Major Is Imp...</td>\n",
        "      <td> http://s3-ec.buzzfed.com/static/2014-05/enhanc...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> 5. But either way you know that you don\u2019t know...</td>\n",
        "      <td> 18 Reasons Why Choosing A College Major Is Imp...</td>\n",
        "      <td> http://s3-ec.buzzfed.com/static/2014-05/enhanc...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "   Unnamed: 0                                               Text  \\\n",
        "0           0  1. Because I just wasn\u2019t one of those people w...   \n",
        "1           1  2. Because there are SO many options to choose...   \n",
        "2           2  3. Some days you hate every subject in the wor...   \n",
        "3           3  4. And other days you\u2019re super ambitious and t...   \n",
        "4           4  5. But either way you know that you don\u2019t know...   \n",
        "\n",
        "                                               Title  \\\n",
        "0  18 Reasons Why Choosing A College Major Is Imp...   \n",
        "1  18 Reasons Why Choosing A College Major Is Imp...   \n",
        "2  18 Reasons Why Choosing A College Major Is Imp...   \n",
        "3  18 Reasons Why Choosing A College Major Is Imp...   \n",
        "4  18 Reasons Why Choosing A College Major Is Imp...   \n",
        "\n",
        "                                                 URL  \n",
        "0  http://s3-ec.buzzfed.com/static/2014-05/enhanc...  \n",
        "1  http://s3-ec.buzzfed.com/static/2014-05/enhanc...  \n",
        "2  http://s3-ec.buzzfed.com/static/2014-05/enhanc...  \n",
        "3  http://s3-ec.buzzfed.com/static/2014-05/enhanc...  \n",
        "4  http://s3-ec.buzzfed.com/static/2014-05/enhanc...  "
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scraping Giphy\n",
      "\n",
      "In case we needed more GIF data, we also built a simple GIF scraper for giphy, a website where people can upload and tag GIFs.\n",
      "\n",
      "Although Giphy tries to keep people from being able to scrape their site, after some exploring we found a trick in their URL encoding that allowed us to query each of the emotion tags in their tag repository and iterate through each page of GIFs.\n",
      "\n",
      "Below, we see the scraper that iterates through each of these emotions and pages and collects about 40,000 GIFs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfs = []\n",
      "emotions = ['angry', 'bored', 'disappointed', 'drunk', 'embarassed', \n",
      "           'excited', 'frustrated', 'happy', 'hungry', 'inspired', \n",
      "           'lonely', 'love', 'nervous', 'pain', 'reaction', 'relaxed', \n",
      "           'sad', 'sassy', 'scared', 'shocked', 'sick', 'stressed', \n",
      "           'surprised', 'suspicious', 'tired', 'unimpressed']\n",
      "\n",
      "for emotion in emotions:\n",
      "    print emotion\n",
      "    urls = ['http://giphy.com/search/' + emotion + '/' + str(x) +'?is=2' for x in range(100)]\n",
      "    for url in urls:\n",
      "        try:\n",
      "            page = urllib2.urlopen(url).read()\n",
      "            soup = BeautifulSoup(page)\n",
      "            images = soup.findAll('div', class_='hoverable-gif')\n",
      "\n",
      "            data = []\n",
      "            for image in images:\n",
      "                tags = [x.text.split('#')[1] for x in image.span.findAll('a')]\n",
      "                url = image.a.figure.img['src'].replace('_s', '')\n",
      "                dfs.append({'tags':tags, 'url':url, 'emotion': emotion})\n",
      "        except:\n",
      "            print 'Done with ' + emotion\n",
      "            break\n",
      "    \n",
      "data = pd.DataFrame(dfs)\n",
      "data.to_csv('data/giphy_emotions_gifs.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "giphy_gifs = pd.read_csv('data/giphy_emotions_gifs.csv')\n",
      "print giphy_gifs.shape\n",
      "giphy_gifs.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(39975, 4)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>emotion</th>\n",
        "      <th>tags</th>\n",
        "      <th>url</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> angry</td>\n",
        "      <td>           [u'angry', u'horse', u'maximus']</td>\n",
        "      <td> http://media2.giphy.com/media/dOZj6qlD8Kwta/20...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> angry</td>\n",
        "      <td>                [u'angry', u'taylor swift']</td>\n",
        "      <td> http://media0.giphy.com/media/ORKQqVjegOvzq/20...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td> angry</td>\n",
        "      <td>          [u'angry', u'coach', u'throwing']</td>\n",
        "      <td> http://media2.giphy.com/media/110gOs75GuUWyY/2...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> angry</td>\n",
        "      <td>                  [u'angry', u'frustrated']</td>\n",
        "      <td> http://media0.giphy.com/media/yI9YaxO7OCz5K/20...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> angry</td>\n",
        "      <td> [u'angry', u'mario', u'nintendo', u'zoom']</td>\n",
        "      <td> http://media0.giphy.com/media/kLEuIxZJh8VG0/20...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "   Unnamed: 0 emotion                                        tags  \\\n",
        "0           0   angry            [u'angry', u'horse', u'maximus']   \n",
        "1           1   angry                 [u'angry', u'taylor swift']   \n",
        "2           2   angry           [u'angry', u'coach', u'throwing']   \n",
        "3           3   angry                   [u'angry', u'frustrated']   \n",
        "4           4   angry  [u'angry', u'mario', u'nintendo', u'zoom']   \n",
        "\n",
        "                                                 url  \n",
        "0  http://media2.giphy.com/media/dOZj6qlD8Kwta/20...  \n",
        "1  http://media0.giphy.com/media/ORKQqVjegOvzq/20...  \n",
        "2  http://media2.giphy.com/media/110gOs75GuUWyY/2...  \n",
        "3  http://media0.giphy.com/media/yI9YaxO7OCz5K/20...  \n",
        "4  http://media0.giphy.com/media/kLEuIxZJh8VG0/20...  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}